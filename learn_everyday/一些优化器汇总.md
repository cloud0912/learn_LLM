![image-20250407184431247](C:\Users\Daniel\AppData\Roaming\Typora\typora-user-images\image-20250407184431247.png)

---

## 初级优化器：奠定基础

在深入了解那些酷炫的高级优化器之前，我们先来回顾一下奠定基础的三种“朴素”方法：批量梯度下降 (BGD)、随机梯度下降 (SGD) 和小批量梯度下降 (Mini-batch GD)。它们构成了后续优化算法的核心思想。

### **1. 批量梯度下降 (Batch Gradient Descent - BGD)**

*   **核心思想:**
    BGD 是最直观的梯度下降形式。顾名思义，“批量”（Batch）指的是**整个训练数据集**。在每次参数更新时，BGD 会计算损失函数在**所有**训练样本上的梯度，然后取平均值（或者总和，效果等价于调整学习率）来指导参数的更新方向。它力求找到一个能让**全局**损失最小化的方向。

*   **公式与步骤:**
    参数更新的公式非常简洁：
    $$
    \theta = \theta - \eta \cdot \nabla_\theta J(\theta)
    $$
    其中：
    *   $\theta$ 代表模型的参数（例如权重和偏置）。
    *   $\eta$ 是学习率 (Learning Rate)，控制每次更新的步长。
    *   $J(\theta)$ 是在**整个训练数据集**上计算的损失函数。
    *   $\nabla_\theta J(\theta)$ 是损失函数 $J(\theta)$ 关于参数 $\theta$ 的梯度。

    **执行步骤：**
    1.  对于整个训练数据集，计算损失函数关于参数 $\theta$ 的梯度 $\nabla_\theta J(\theta)$。
    2.  使用上述公式更新参数 $\theta$。
    3.  重复步骤 1 和 2 直到满足停止条件（例如达到最大迭代次数或损失收敛）。

*   **伪代码实现:**

    ```python
    # epochs: 训练轮数
    # dataset: 包含所有训练数据的集合
    # params: 模型参数
    # lr: 学习率
    # eval_grad: 计算梯度的函数

    for i in range(epochs):
        # 在 **整个数据集** 上计算梯度
        grad = eval_grad(losses, dataset, params)
        # 更新参数
        params = params - lr * grad
    ```

*   **优缺点:**
    *   **优点:**
        *   **精确的梯度方向:** 由于使用了全部数据，每次更新的梯度方向都准确地指向当前参数下全局损失下降最快的方向。
        *   **稳定收敛:** 对于凸优化问题，保证能收敛到全局最优解；对于非凸优化问题，能稳定收敛到局部最优解（不易震荡）。
    *   **缺点:**
        *   **计算成本高:** 每次参数更新都需要遍历整个数据集来计算梯度，当数据集非常大时，这会变得极其缓慢。
        *   **内存需求大:** 可能需要将整个数据集加载到内存中以计算梯度。
        *   **无法在线学习:** 不能在有新数据到来时实时更新模型，必须等待收集完整（或一批）数据。

### **2. 随机梯度下降 (Stochastic Gradient Descent - SGD)**

*   **核心思想:**
    为了解决 BGD 在大数据集上的计算效率问题，SGD 采取了更为激进的策略。它**每次参数更新只随机选择一个训练样本**来计算梯度。这就像 BGD 在黑暗中摸索全局最优方向，而 SGD 则像一个有点醉醺醺的人，每次只凭感觉（单个样本的梯度）走一步，虽然方向不一定完美，但速度快得多。

*   **公式与步骤:**
    更新公式变为针对单个样本 $(x^{(i)}, y^{(i)})$：
    $$
    \theta_{t+1} = \theta_t - \eta_t \nabla_\theta J(\theta_t; x^{(i)}, y^{(i)})
    $$
    其中：
    *   $\theta_t$ 是在时间步 $t$ 的模型参数。
    *   $\eta_t$ 是可能随时间调整的学习率。
    *   $J(\theta_t; x^{(i)}, y^{(i)})$ 是损失函数在**单个样本** $(x^{(i)}, y^{(i)})$ 上的值。
    *   $\nabla_\theta J(\theta_t; x^{(i)}, y^{(i)})$ 是损失函数在该单个样本上关于参数 $\theta_t$ 的梯度。

    **执行步骤：**
    1.  随机打乱训练数据集的顺序。
    2.  对于数据集中的**每一个**样本 $(x^{(i)}, y^{(i)})$：
        a. 计算损失函数在该样本上的梯度 $\nabla_\theta J(\theta; x^{(i)}, y^{(i)})$。
        b. 使用上述公式更新参数 $\theta$。
    3.  完成对所有样本的一次遍历称为一个 epoch。重复执行多个 epoch 直到满足停止条件。

*   **伪代码实现:**

    ```python
    # epochs: 训练轮数
    # dataset: 包含所有训练数据的集合
    # params: 模型参数
    # lr: 学习率
    # eval_grad: 计算梯度的函数

    for i in range(epochs):
        # 每个 epoch 开始前打乱数据顺序
        random_shuffle(dataset)
        # 遍历数据集中的 **每一个** 样本
        for data_i in dataset:
            # 在单个样本上计算梯度
            grad = eval_grad(losses, data_i, params)
            # 更新参数
            params = params - lr * grad
    ```

*   **优缺点:**
    *   **优点:**
        *   **更新速度快:** 每次更新计算量非常小，训练速度快。
        *   **适用于大数据集和在线学习:** 可以处理无法一次性载入内存的大数据集，并且可以随时根据新来的数据进行模型更新（在线学习）。
        *   **可能跳出局部最优:** 梯度更新的随机性（高方差）有时能帮助优化器跳出较差的局部最优解，可能找到更好的最优解。
    *   **缺点:**
        *   **高方差更新:** 每次更新只基于单个样本，梯度估计噪声很大，导致损失函数下降过程非常震荡。
        *   **收敛困难:** 由于震荡，可能难以精确收敛到最优解，常常在最优点附近徘徊。通常需要仔细调整学习率，例如使用学习率衰减策略 (Learning Rate Annealing/Decay) 来改善收敛性。

### **3. 小批量梯度下降 (Mini-Batch Gradient Descent - MBGD)**

*   **核心思想:**
    MBGD 是 BGD 和 SGD 之间的一个**完美折中**。它既不像 BGD 那样使用全部数据（太慢），也不像 SGD 那样只用一个样本（太随机），而是每次更新时**随机选择一小批（mini-batch）** 训练样本（例如 32, 64, 128 个）来计算梯度。这在保证了较快更新速度的同时，也通过小批量样本梯度的平均化降低了更新的方差，使得收敛过程更加稳定。

*   **公式与步骤:**
    更新公式使用一个小批量的数据 $B = \{(x^{(i)}, y^{(i)}), ..., (x^{(i+n-1)}, y^{(i+n-1)})\}$：
    $$
    \theta = \theta - \eta \cdot \nabla_\theta J(\theta; B)
    $$
    其中：
    *   $n$ 是小批量的大小 (batch size)。
    *   $J(\theta; B) = \frac{1}{n} \sum_{j=i}^{i+n-1} J(\theta; x^{(j)}, y^{(j)})$ 是在小批量 $B$ 上的平均损失。
    *   $\nabla_\theta J(\theta; B)$ 是该平均损失关于参数 $\theta$ 的梯度。

    **执行步骤：**
    1.  随机打乱训练数据集的顺序。
    2.  将数据集划分为若干个小批量。
    3.  对于**每一个**小批量 $B$：
        a. 计算损失函数在该小批量上的平均梯度 $\nabla_\theta J(\theta; B)$。
        b. 使用上述公式更新参数 $\theta$。
    4.  完成对所有小批量的一次遍历称为一个 epoch。重复执行多个 epoch 直到满足停止条件。

*   **伪代码实现:**

    ```python
    # epochs: 训练轮数
    # dataset: 包含所有训练数据的集合
    # batch_size: 小批量大小
    # params: 模型参数
    # lr: 学习率
    # eval_grad: 计算梯度的函数

    for i in range(epochs):
        # 每个 epoch 开始前打乱数据顺序
        random_shuffle(dataset)
        # 将数据集划分为小批量
        for batch_data in dataset.batch(batch_size):
            # 在一个小批量上计算梯度
            grad = eval_grad(losses, batch_data, params)
            # 更新参数
            params = params - lr * grad
    ```

*   **优缺点:**
    *   **优点:**
        *   **计算效率高:** 相比 BGD，每次更新计算量显著减少。
        *   **收敛更稳定:** 相比 SGD，梯度估计的方差减小，损失下降曲线更平滑，收敛更稳定。
        *   **利用硬件并行:** 可以高效利用现代 GPU/TPU 的并行计算能力，通过向量化操作加速小批量梯度计算。
    *   **缺点:**
        *   **引入新超参:** 需要额外选择一个合适的批量大小 (batch size)。
        *   **梯度仍有噪声:** 虽然比 SGD 好，但相比 BGD，梯度仍然存在一定的噪声。

*   **实践中的王者:**
    **Mini-batch GD 是目前深度学习中最常用的优化方法**。当我们提到 "SGD" 时，通常指的就是 Mini-batch SGD。它很好地平衡了 BGD 的稳定性和 SGD 的效率。

### **初级优化器的局限性**

尽管 Mini-batch GD 是一个巨大的进步，但这三种基础优化器仍然面临一些共同的挑战：

1.  **学习率选择困难:** 选择一个合适的全局学习率 $\eta$ 非常棘手。太小导致收敛缓慢，太大则可能导致震荡甚至发散。
2.  **学习率调度预设:** 很多时候需要预先设定学习率的调整策略（例如逐步减小），这种策略无法自动适应数据集的特性。
3.  **对所有参数一视同仁:** 所有参数都使用相同的学习率进行更新。但对于稀疏数据或不同频率出现的特征，我们可能希望对不同参数应用不同的更新速率。
4.  **易陷局部最优/鞍点:** 对于非凸损失函数（深度学习中常见），这些优化器（尤其是 BGD 和 Mini-batch GD 在梯度接近零时）容易陷入局部最小值或鞍点，难以找到更好的解。

正是为了解决这些问题，后续更高级的优化算法（如 Momentum, AdaGrad, RMSprop, Adam 等）应运而生。接下来，我们将深入探讨这些高级优化器是如何克服上述挑战的。

---

## 进阶优化器：引入惯性与自适应

基础优化器虽然有效，但在面对复杂损失曲面（如深度学习中常见的）时，它们的局限性变得明显。进阶优化器通过引入“记忆”（如动量）或自适应调整学习率来克服这些挑战，旨在更快、更稳定地找到最优解。

### **1. 动量 (Momentum)**

* **核心思想:**
  想象一个滚下山坡的小球。由于惯性（动量），它不仅会沿着当前最陡峭的方向（梯度）滚动，还会保持一部分之前的速度。Momentum 优化器模拟了这个物理过程。它引入了一个“动量”项（通常表示为速度 $v$），该项是过去梯度的指数加权移动平均。参数更新不仅取决于当前的梯度，还取决于这个累积的动量。这有助于：

  1.  在梯度方向一致的维度上**加速收敛**。
  2.  在梯度方向变化剧烈的维度上**抑制震荡**（例如，在狭窄的“峡谷”地形中，垂直于峡谷方向的梯度会相互抵消）。
  3.  帮助**冲出局部最小值或平坦区域**，因为即使当前梯度很小或为零，累积的动量仍然可以推动参数前进。

* **公式与步骤:**

  1. 初始化动量项 $v_0 = 0$。

  2. 在每个时间步 $t$：
     a. 计算当前参数 $\theta_t$ 下的梯度 $\nabla J(\theta_t)$ （通常使用 mini-batch）。
     b. 更新动量项 $v_t$：
     $$
        v_t = \gamma v_{t-1} + \eta \nabla J(\theta_t)
     $$

        *   $\gamma$ 是动量系数（通常取 0.9 左右），控制历史动量衰减的程度。$\gamma=0$ 时退化为标准 SGD/Mini-batch GD。
        *   $\eta$ 是学习率。

     c. 更新参数 $\theta$：
     $$
        \theta_{t+1} = \theta_t - v_t
     $$
        参数的更新量现在是动量项 $v_t$，它结合了当前梯度和历史梯度信息。

* **伪代码实现:**

  ```python
  # gamma: 动量系数 (e.g., 0.9)
  # lr: 学习率
  # params: 模型参数
  # v: 动量项 (与 params 形状相同, 初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          grad = eval_grad(losses, batch_data, params)
          # 更新动量
          v = gamma * v + lr * grad
          # 更新参数
          params = params - v
  ```

* **优缺点:**

  *   **优点:**
      *   **加速收敛:** 特别是在梯度方向稳定的维度上，收敛速度通常比 SGD/Mini-batch GD 快。
      *   **减少震荡:** 动量可以平滑更新轨迹，减少在某些方向上的来回震荡。
      *   **有助于跳出局部最优:** 累积的动量可能帮助“冲过”浅的局部最小值或鞍点。
  *   **缺点:**
      *   **引入新超参:** 需要额外调整动量系数 $\gamma$。
      *   **仍需调整学习率:** 学习率 $\eta$ 的选择依然重要。
      *   **可能冲过头:** 在某些情况下，动量可能导致优化器冲过最优点，尤其是在接近最优解时。

### **2. Nesterov 加速梯度 (Nesterov Accelerated Gradient - NAG)**

* **核心思想:**
  NAG 是对标准 Momentum 的一种改进，它引入了“预见性”或“前瞻性”。标准 Momentum 首先计算当前位置的梯度，然后加上累积的动量来决定下一步的位置。而 NAG 则认为，既然我们无论如何都要根据动量 $v_{t-1}$ 移动一段距离（由 $\gamma v_{t-1}$ 决定），那么我们不如**先大致跳到那个“预测”的未来位置** $\theta_t - \gamma v_{t-1}$，**然后在那个未来位置计算梯度**，再用这个更“聪明”的梯度来修正最终的移动方向。这就像下坡时，如果预见到前方即将变成上坡，会提前减速，从而避免冲得太猛。

* **公式与步骤:**

  1. 初始化动量项 $v_0 = 0$。

  2. 在每个时间步 $t$：
     a. 计算“预测”位置的梯度：$\nabla J(\theta_t - \gamma v_{t-1})$。这是 NAG 与标准 Momentum 的核心区别。
     b. 更新动量项 $v_t$：
     $$
        v_t = \gamma v_{t-1} + \eta \nabla J(\theta_t - \gamma v_{t-1})
     $$
     c. 更新参数 $\theta$：
     $$
        \theta_{t+1} = \theta_t - v_t
     $$
     (注意：存在一些等价的公式表示形式，但核心思想是计算“预测”位置的梯度)

* **伪代码实现:**

  ```python
  # gamma: 动量系数 (e.g., 0.9)
  # lr: 学习率
  # params: 模型参数
  # v: 动量项 (与 params 形状相同, 初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          # 1. 计算预测位置
          params_lookahead = params - gamma * v
          # 2. 在预测位置计算梯度
          grad = eval_grad(losses, batch_data, params_lookahead)
          # 3. 更新动量 (使用 lookahead 梯度)
          v = gamma * v + lr * grad
          # 4. 更新参数 (使用更新后的动量)
          params = params - v
  ```

* **优缺点:**

  *   **优点:**
      *   **通常比标准 Momentum 收敛更快、更稳定:** “预见性”使其能更有效地响应梯度的变化，减少震荡和过冲。
      *   **在某些问题上表现更好:** 特别是在一些具有复杂曲面的优化问题上。
  *   **缺点:**
      *   **计算略微复杂:** 需要计算预测位置的梯度。
      *   **超参数调整:** 仍然需要调整学习率 $\eta$ 和动量系数 $\gamma$。

### **3. 平均随机梯度下降 (Averaged Stochastic Gradient Descent - ASGD)**

* **核心思想:**
  ASGD 旨在提高 SGD（或 Mini-batch SGD）的收敛稳定性和泛化能力。它的核心思想**不是**修改单步的更新规则，而是**在训练过程中，对 SGD 产生的参数序列进行平均**。它认为，虽然 SGD 的每一步参数 $\theta_t$ 可能因为噪声而围绕最优解震荡，但这些参数的**平均值** $\bar{\theta}$ 会更接近最优解，并且更稳定。通常，这个平均操作会在训练进行一段时间（"burn-in" 阶段）之后才开始，或者使用某种形式的加权平均（如指数移动平均）。

* **公式与步骤:** (这里展示最简单的算术平均形式)

  1. 初始化参数 $\theta_0$。

  2. 在每个时间步 $t = 1, 2, ... T$：
     a. 使用标准 SGD 或 Mini-batch SGD 计算梯度 $g_t = \nabla J(\theta_{t-1}; \text{data}_t)$。
     b. 更新瞬时参数：$\theta_t = \theta_{t-1} - \eta_t g_t$。
     c. **维护参数的平均值**（通常从某个迭代 $k$ 开始）：
     $$
        \bar{\theta}_t = \frac{1}{t-k+1} \sum_{i=k}^{t} \theta_i \quad (\text{for } t \ge k)
     $$
        (实践中常用滑动平均来避免存储所有历史参数: $\bar{\theta}_t = \alpha \bar{\theta}_{t-1} + (1-\alpha) \theta_t$)

  3. **最终使用的模型参数是平均参数 $\bar{\theta}_T$**，而不是最后一次迭代的参数 $\theta_T$。

* **伪代码实现 (使用滑动平均):**

  ```python
  # lr: 学习率 (可以是固定的或衰减的)
  # alpha: 滑动平均系数 (e.g., 0.99)
  # params: 瞬时模型参数
  # avg_params: 平均模型参数 (与 params 形状相同, 初始化为 params)
  # eval_grad: 计算梯度的函数 (基于 SGD 或 mini-batch)
  # start_averaging_step: 从哪个迭代步开始平均 (e.g., 1000)
  
  step = 0
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          grad = eval_grad(losses, batch_data, params)
          # 1. 更新瞬时参数
          params = params - lr * grad
          step += 1
          # 2. 更新平均参数 (如果达到开始平均的步骤)
          if step >= start_averaging_step:
              avg_params = alpha * avg_params + (1 - alpha) * params
          else: # 在开始平均之前，让平均参数跟随瞬时参数
              avg_params = params
  
  # 训练结束后，使用 avg_params 作为最终模型
  final_model_params = avg_params
  ```

* **优缺点:**

  *   **优点:**
      *   **更好的收敛性:** 平均操作可以平滑 SGD 的震荡，可能收敛到更接近最优解的点。
      *   **提高泛化能力:** 经验和理论表明，平均后的参数通常具有更好的泛化性能。
      *   **理论支持:** 在某些条件下（如凸优化），ASGD 具有比 SGD 更优的理论收敛速率。
  *   **缺点:**
      *   **额外开销:** 需要存储和更新平均参数，增加少量内存和计算。
      *   **需要决定何时开始平均:** 如果不是从头开始平均，需要确定一个合适的 `start_averaging_step`。
      *   **可能不如自适应方法快:** 对于某些非凸问题，收敛速度可能不如 Adam 等自适应方法。

---

## 智能优化器：自适应学习率

前面的优化器（包括 Momentum 和 NAG）通常对所有参数使用相同的全局学习率 $\eta$。然而，在实际问题中，不同参数的重要性、更新频率或梯度的尺度可能差异很大（例如，处理稀疏特征时）。智能优化器（也称自适应学习率优化器）的核心思想是**为模型中的每个参数自动调整其学习率**。

### **1. Rprop (Resilient Backpropagation)**

* **核心思想:**
  Rprop 是一种较早的自适应方法，主要用于**全批量 (full-batch) 梯度下降**。它的核心思想非常独特：**完全忽略梯度的大小（magnitude），只关注梯度的符号（sign）**。它为每个参数维护一个独立的“更新值”（step size，类似于学习率）。

  *   如果一个参数的梯度连续两次符号相同，说明优化方向一致，就**增大**该参数的更新值（加速前进）。
  *   如果梯度符号发生改变，说明可能越过了最小值，就**减小**更新值，并且**撤销**上一步的更新（通过符号判断更新方向）。
      这种方式使得 Rprop 对梯度的大小不敏感，只关心方向是否正确，从而能快速穿越平坦区域（梯度小但符号一致）并小心地接近最优解（梯度符号变化）。

* **公式与步骤:** (存在多种 Rprop 变体，这里描述 Rprop+ 的核心思想)

  更新规则：
  $$
  \Delta_i^{(t)} = \begin{cases}
  \min(\eta_+ \Delta_i^{(t-1)}, \Delta_{\max}) & \text{if } \nabla_t \cdot \nabla_{t-1} > 0 \\
  \max(\eta_- \Delta_i^{(t-1)}, \Delta_{\min}) & \text{if } \nabla_t \cdot \nabla_{t-1} < 0 \\
  \Delta_i^{(t-1)} & \text{otherwise}
  \end{cases}
  $$
  参数更新：
  $$
  \theta_i^{(t)} = \theta_i^{(t-1)} - \text{sign}(\nabla_i^{(t)}) \cdot \Delta_i^{(t)}
  $$

  1. 为每个参数 $\theta_i$ 初始化一个更新值 $\Delta_i$（例如，一个小的正数 $\Delta_0$），并初始化上一步的梯度 $g_{i, t-1} = 0$。

  2. 设置更新值增加因子 $\eta^+ > 1$ (e.g., 1.2) 和减少因子 $0 < \eta^- < 1$ (e.g., 0.5)。设置更新值的上下限 $\Delta_{\max}$ 和 $\Delta_{\min}$。

  3. 在每个时间步 $t$（通常基于整个数据集计算梯度 $g_t = \nabla J(\theta_t)$）：

     a. 对于每个参数 $\theta_i$：
         i.  检查当前梯度 $g_{i,t}$ 和上一步梯度 $g_{i, t-1}$ 的乘积 $p = g_{i, t-1} \cdot g_{i, t}$。
         ii. **如果 $p > 0$ (符号相同):**

     ​		增加更新值: $\Delta_{i,t} = \min(\Delta_{i, t-1} \cdot \eta^+, \Delta_{\max})$

     ​		更新参数: $\theta_{i, t+1} = \theta_{i, t} - \text{sign}(g_{i,t}) \cdot \Delta_{i,t}$

     ​		记录当前梯度: $g_{i, t} \leftarrow g_{i, t}$ (原始梯度)
     ​    iii. **如果 $p < 0$ (符号相反):**

     ​		减少更新值: $\Delta_{i,t} = \max(\Delta_{i, t-1} \cdot \eta^-, \Delta_{\min})$

     ​		**不更新参数或回退一步:** (不同变体处理不同，常见的是 $\theta_{i, t+1} = \theta_{i, t}$ 或者 $\theta_{i, t+1} = \theta_{i, t} - \theta_{i, t-1}$ 中的更新量，即撤销上一步)

     ​		**将当前梯度置零:** $g_{i, t} \leftarrow 0$ (阻止下次迭代基于这次错误的符号进行加速)
     ​    iv. **如果 $p = 0$:**

     ​		保持更新值: $\Delta_{i,t} = \Delta_{i, t-1}$

     ​		更新参数: $\theta_{i, t+1} = \theta_{i, t} - \text{sign}(g_{i,t}) \cdot \Delta_{i,t}$

     ​		记录当前梯度: $g_{i, t} \leftarrow g_{i, t}$
     b. 更新所有参数后，存储当前的梯度 $g_{i,t}$ 作为下一次迭代的 $g_{i, t-1}$。

* **伪代码实现:** (简化版，展示核心逻辑)

  ```python
  # delta: 每个参数的更新值 (初始化为 delta_0)
  # prev_grad: 上一步的梯度 (初始化为 0)
  # eta_plus, eta_minus: 更新值增减因子
  # delta_max, delta_min: 更新值上下限
  # params: 模型参数
  
  # Rprop 通常用于 full-batch
  for i in range(epochs):
      grad = eval_grad(losses, dataset, params) # Full-batch gradient
      for j in range(len(params)):
          p = prev_grad[j] * grad[j]
          if p > 0:
              delta[j] = min(delta[j] * eta_plus, delta_max)
              update = -sign(grad[j]) * delta[j]
              params[j] = params[j] + update
              prev_grad[j] = grad[j]
          elif p < 0:
              delta[j] = max(delta[j] * eta_minus, delta_min)
              # Rprop- 变体: 撤销上一步 (如果记录了上一步更新量)
              # params[j] = params[j] - prev_update[j] # (假设上一步更新量 prev_update[j] 被记录)
              prev_grad[j] = 0 # 重要: 清零梯度
          else: # p == 0
              update = -sign(grad[j]) * delta[j]
              params[j] = params[j] + update
              prev_grad[j] = grad[j]
      # (如果使用 Rprop-，需要记录 prev_update)
  ```

* **优缺点:**

  *   **优点:**
      *   **对学习率不敏感:** 不需要设置全局学习率 $\eta$。
      *   **收敛快:** 对于某些问题，尤其是在全批量模式下，收敛速度很快。
      *   **鲁棒性:** 对梯度的大小不敏感，只关心方向。
  *   **缺点:**
      *   **不适用于 Mini-batch:** Rprop 的核心机制依赖于梯度的稳定符号变化，这在 Mini-batch 的随机梯度下效果不佳，梯度符号可能因噪声频繁变化。这使得它在现代深度学习中很少使用。
      *   **引入多个超参:** 需要设置 $\eta^+, \eta^-, \Delta_0, \Delta_{\max}, \Delta_{\min}$。

### **2. AdaGrad (Adaptive Gradient Algorithm)**

* **核心思想:**
  AdaGrad 的核心思想是：**给不经常更新的参数（梯度稀疏）较大的学习率，给经常更新的参数（梯度密集）较小的学习率**。它通过累积每个参数**迄今为止所有梯度值的平方和**来实现这一点。在更新参数时，全局学习率 $\eta$ 会被这个累积值的平方根所除（分母）。因此，如果一个参数的梯度一直很大或经常非零，它的累积平方和就会很大，导致其实际学习率变小；反之，如果一个参数的梯度很小或经常为零，累积平方和增长缓慢，其实际学习率相对较大。

* **公式与步骤:**

  1. 初始化梯度累积平方和 $G_0 = 0$ （一个与参数 $\theta$ 同形状的向量或矩阵，所有元素为0）。

  2. 设置全局学习率 $\eta$ 和一个小的稳定项 $\epsilon$ (e.g., $10^{-8}$)。

  3. 在每个时间步 $t$：
     a. 计算当前参数 $\theta_t$ 下的梯度 $g_t = \nabla J(\theta_t)$ （通常使用 mini-batch）。
     b. **累积梯度平方:**
     $$
        G_t = G_{t-1} + g_t \odot g_t
     $$
     $\odot$ 表示逐元素相乘。$G_t$ 的每个元素 $G_{t, ii}$ 累积了第 $i$ 个参数的历史梯度平方和。
     c. **计算参数更新:**
     $$
        \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t
     $$

        *   除法和平方根也是逐元素进行的。$\frac{\eta}{\sqrt{G_t + \epsilon}}$ 构成了每个参数的自适应学习率。

* **伪代码实现:**

  ```python
  # lr: 全局学习率
  # epsilon: 数值稳定项 (e.g., 1e-8)
  # params: 模型参数
  # grad_squared_sum: 累积梯度平方和 (与 params 形状相同, 初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          grad = eval_grad(losses, batch_data, params)
          # 累积梯度平方和
          grad_squared_sum = grad_squared_sum + grad * grad
          # 计算调整后的梯度 (含自适应学习率)
          adjusted_grad = grad / (sqrt(grad_squared_sum) + epsilon)
          # 更新参数
          params = params - lr * adjusted_grad
  ```

* **优缺点:**

  *   **优点:**
      *   **自适应学习率:** 自动为不同参数调整学习率，无需手动精细调整。
      *   **特别适合稀疏数据:** 对不常出现的特征（参数梯度稀疏）给予较大的更新步长，效果显著。
  *   **缺点:**
      *   **学习率单调递减:** 由于梯度平方和 $G_t$ 是不断累积的，分母会持续增大，导致学习率最终会变得非常小，可能在训练后期过早地停止学习，尤其是在非凸优化中可能无法有效探索。这是 AdaGrad 最主要的局限性。
      *   **存储历史梯度矩阵消耗内存为参数量的2倍**

好的，我们继续来润色 AdaDelta, RMSprop 和 Adam 这三个非常重要的自适应学习率优化器。

---

### **3. AdaDelta**

* **核心思想:**
  AdaDelta 是对 AdaGrad 的一个重要改进，旨在解决 AdaGrad 学习率**单调递减**并最终趋于零的问题。AdaGrad 的问题根源在于分母中累积了**所有**历史梯度的平方和。AdaDelta 的巧妙之处在于：

  1.  **限制历史梯度窗口:** 它不像 AdaGrad 那样累积所有历史梯度平方，而是使用**指数加权移动平均 (EMA)** 来计算近期梯度平方的均值（类似于 RMSprop）。这防止了分母无限增大。
  2.  **消除全局学习率:** 更进一步地，AdaDelta 注意到优化器更新步长（$\Delta \theta$）与参数 $\theta$ 本身应该具有相同的“单位”（或者说量纲）。它也对**近期参数更新量（$\Delta \theta$）的平方**计算了 EMA。最终的更新步长由近期更新量 EMA 的平方根除以近期梯度平方 EMA 的平方根来决定，**从而巧妙地消除了对全局学习率 $\eta$ 的依赖**。

* **公式与步骤:**
  $$
  \begin{aligned}
  s_t &= \rho s_{t-1} + (1-\rho)g_t^2 \quad &\text{(梯度平方累积)} \\
  \Delta\theta_t &= -\frac{\sqrt{\delta_{t-1} + \epsilon}}{\sqrt{s_t + \epsilon}}g_t \quad &\text{(自适应更新量)} \\
  \theta_t &= \theta_{t-1} + \Delta\theta_t \quad &\text{(参数更新)} \\
  \delta_t &= \rho \delta_{t-1} + (1-\rho)\Delta\theta_t^2 \quad &\text{(更新量累积)}
  \end{aligned}
  $$
  

  1. 初始化累积梯度平方 $E[g^2]_0 = 0$ 和累积更新量平方 $E[\Delta \theta^2]_0 = 0$ （与参数 $\theta$ 同形状的向量或矩阵）。

  2. 设置衰减系数 $\rho$ (通常为 0.9 或 0.95) 和一个小的稳定项 $\epsilon$ (e.g., $10^{-6}$)。

  3. 在每个时间步 $t$：
     a. 计算当前参数 $\theta_t$ 下的梯度 $g_t = \nabla J(\theta_t)$ （通常使用 mini-batch）。
     b. **更新近期梯度平方的 EMA:**
     $$
        E[g^2]_t = \rho E[g^2]_{t-1} + (1 - \rho) g_t^2
     $$
     ​    $g_t^2$ 表示 $g_t \odot g_t$ (逐元素平方)。
     c. **计算当前的更新量 $\Delta \theta_t$:** (注意：这里需要使用**上一步**的累积更新量)
     $$
        \Delta \theta_t = - \frac{\sqrt{E[\Delta \theta^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_t + \epsilon}} \odot g_t
     $$
     ​    这里的 $\sqrt{E[\Delta \theta^2]_{t-1} + \epsilon}$ 起到了类似学习率的作用，但它是自适应计算出来的。
     d. **更新近期更新量平方的 EMA:** (使用**当前**计算出的 $\Delta \theta_t$)
     $$
        E[\Delta \theta^2]_t = \rho E[\Delta \theta^2]_{t-1} + (1 - \rho) (\Delta \theta_t)^2
     $$
     ​    $(\Delta \theta_t)^2$ 表示 $\Delta \theta_t \odot \Delta \theta_t$。
     e. **应用更新:**
     $$
        \theta_{t+1} = \theta_t + \Delta \theta_t
     $$
        (注意：原始论文中 $\Delta \theta_t$ 前有负号，所以这里是加号)

* **伪代码实现:**

  ```python
  # rho: 衰减系数 (e.g., 0.95)
  # epsilon: 数值稳定项 (e.g., 1e-6)
  # params: 模型参数
  # accum_grad_sq: 累积梯度平方的 EMA (E[g^2], 初始化为 0)
  # accum_update_sq: 累积更新量平方的 EMA (E[Delta_theta^2], 初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          grad = eval_grad(losses, batch_data, params)
  
          # 更新梯度平方的 EMA
          accum_grad_sq = rho * accum_grad_sq + (1 - rho) * grad * grad
  
          # 计算更新量 (使用上一时刻的 accum_update_sq)
          update = -(sqrt(accum_update_sq + epsilon) / sqrt(accum_grad_sq + epsilon)) * grad
  
          # 更新更新量平方的 EMA (使用当前的 update)
          accum_update_sq = rho * accum_update_sq + (1 - rho) * update * update
  
          # 更新参数
          params = params + update
  ```

* **优缺点:**

  *   **优点:**
      *   **无需设置全局学习率:** 这是 AdaDelta 最显著的特点，减少了一个需要调整的关键超参数。
      *   **解决了 AdaGrad 学习率消失问题:** 通过 EMA 限制了历史窗口。
      *   **对噪声和超参数相对鲁棒:** 论文声称其对噪声、模型结构和数据模式有较好的鲁棒性。
  *   **缺点:**
      *   **性能可能不稳定:** 实践中，有时训练过程可能不稳定，或者收敛速度不如 Adam 等其他方法。
      *   **对衰减系数 $\rho$ 敏感:** 虽然没有学习率，但 $\rho$ 的选择仍然对性能有影响。
      *   **后期更新量可能减小:** 虽然解决了 AdaGrad 的问题，但 $E[\Delta \theta^2]$ 可能也会变得很小，导致后期学习缓慢（虽然不如 AdaGrad 严重）。
      *   **实际应用相对较少:** 相比 RMSprop 和 Adam，AdaDelta 在当前深度学习实践中的使用频率较低。

---

### **4. RMSprop (Root Mean Square Propagation)**

* **核心思想:**
  RMSprop (由 Geoffrey Hinton 在其 Coursera 课程中提出，非正式发表) 同样是为了解决 AdaGrad 学习率急剧下降的问题。它的思路比 AdaDelta 更直接：**仍然保留全局学习率 $\eta$，但用梯度的指数加权移动平均 (EMA) 来调整它**。具体来说，它计算近期梯度平方的 EMA ($E[g^2]$)，然后将全局学习率 $\eta$ 除以这个 EMA 的平方根。这样，如果近期梯度一直很大，分母增大，有效学习率减小；如果近期梯度很小，分母减小，有效学习率增大。相比 AdaGrad 的全局累积，EMA 只关注近期的梯度信息，避免了学习率过早衰减至零。

* **公式与步骤:**

  1. 初始化累积梯度平方 $E[g^2]_0 = 0$ （与参数 $\theta$ 同形状的向量或矩阵）。

  2. 设置全局学习率 $\eta$ (e.g., 0.001)，衰减系数 $\rho$ (通常为 0.9)，以及一个小的稳定项 $\epsilon$ (e.g., $10^{-8}$ 或 $10^{-6}$)。

  3. 在每个时间步 $t$：
     a. 计算当前参数 $\theta_t$ 下的梯度 $g_t = \nabla J(\theta_t)$ （通常使用 mini-batch）。
     b. **更新近期梯度平方的 EMA:**
     $$
        E[g^2]_t = \rho E[g^2]_{t-1} + (1 - \rho) g_t^2
     $$
     c. **计算参数更新:**
     $$
        \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \odot g_t
     $$

* **伪代码实现:**

  ```python
  # lr: 全局学习率 (e.g., 0.001)
  # rho: 衰减系数 (e.g., 0.9)
  # epsilon: 数值稳定项 (e.g., 1e-8)
  # params: 模型参数
  # accum_grad_sq: 累积梯度平方的 EMA (E[g^2], 初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          grad = eval_grad(losses, batch_data, params)
  
          # 更新梯度平方的 EMA
          accum_grad_sq = rho * accum_grad_sq + (1 - rho) * grad * grad
  
          # 计算调整后的梯度 (含自适应学习率)
          adjusted_grad = grad / (sqrt(accum_grad_sq) + epsilon)
  
          # 更新参数
          params = params - lr * adjusted_grad
  ```

* **优缺点:**

  *   **优点:**
      *   **有效解决 AdaGrad 学习率消失问题:** EMA 机制效果显著。
      *   **自适应学习率:** 能够根据近期梯度大小调整每个参数的学习率。
      *   **适合非平稳目标:** 对于损失函数景观变化较快的情况（如 RNN 训练）表现较好。
      *   **计算相对简单:** 相比 AdaDelta 和 Adam，实现略简单。
  *   **缺点:**
      *   **仍需设置全局学习率 $\eta$:** $\eta$ 的选择依然重要，需要调整。
      *   **引入衰减系数 $\rho$:** 需要额外调整超参数 $\rho$。
      *   **可能缺少动量:** RMSprop 本身没有动量项，有时结合 Nesterov Momentum (Nadam) 效果更好。

---

### **5. Adam (Adaptive Moment Estimation)**

* **核心思想:**
  Adam 可以看作是**结合了 Momentum 和 RMSprop 优点**的集大成者。它同时利用了梯度的**一阶矩估计（Momentum项）**和**二阶矩估计（类似RMSprop的梯度平方EMA项）**。

  1.  **一阶矩 (Momentum):** 它使用梯度的指数加权移动平均 $m_t$ 来估计梯度的均值，这包含了动量信息，有助于加速收敛和越过平坦区域/局部最优。
  2.  **二阶矩 (Adaptive LR):** 它使用梯度**平方**的指数加权移动平均 $v_t$ 来估计梯度的二阶矩（未中心化的方差），用于像 RMSprop 那样自适应地调整每个参数的学习率（梯度大的地方学习率小，梯度小的地方学习率大）。
  3.  **偏差修正:** 由于 $m_t$ 和 $v_t$ 初始化为 0，在训练初期，它们的值会偏向于 0。Adam 通过计算偏差修正后的 $\hat{m}_t$ 和 $\hat{v}_t$ 来抵消这种初期偏差，使得估计在开始阶段更准确。

* **公式与步骤:**

  1. 初始化一阶矩估计 $m_0 = 0$ 和二阶矩估计 $v_0 = 0$ （与参数 $\theta$ 同形状）。初始化时间步 $t = 0$。

  2. 设置学习率 $\eta$ (e.g., 0.001)，一阶矩衰减系数 $\beta_1$ (通常 0.9)，二阶矩衰减系数 $\beta_2$ (通常 0.999)，以及稳定项 $\epsilon$ (e.g., $10^{-8}$)。

  3. 在每个时间步 $t$ (从 1 开始)：
     a. $t \leftarrow t + 1$
     b. 计算当前参数 $\theta_{t-1}$ 下的梯度 $g_t = \nabla J(\theta_{t-1})$ （通常使用 mini-batch）。
     c. **更新有偏一阶矩估计:**
     $$
        m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
     $$
     d. **更新有偏二阶矩估计:**
     $$
        v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
     $$
     e. **计算偏差修正后的一阶矩估计:**
     $$
        \hat{m}_t = \frac{m_t}{1 - \beta_1^t}
     $$
     f. **计算偏差修正后的二阶矩估计:**
     $$
        \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
     $$
     g. **计算参数更新:**
     $$
        \theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
     $$

* **伪代码实现:**

  ```python
  # lr: 学习率 (e.g., 0.001)
  # beta1, beta2: 衰减系数 (e.g., 0.9, 0.999)
  # epsilon: 数值稳定项 (e.g., 1e-8)
  # params: 模型参数
  # m: 一阶矩估计 (初始化为 0)
  # v: 二阶矩估计 (初始化为 0)
  # t: 时间步 (初始化为 0)
  # eval_grad: 计算梯度的函数 (通常基于 mini-batch)
  
  for i in range(epochs):
      for batch_data in dataset.batch(batch_size):
          t = t + 1
          grad = eval_grad(losses, batch_data, params)
  
          # 更新有偏矩估计
          m = beta1 * m + (1 - beta1) * grad
          v = beta2 * v + (1 - beta2) * grad * grad
  
          # 计算偏差修正后的矩估计
          m_hat = m / (1 - beta1**t)
          v_hat = v / (1 - beta2**t)
  
          # 更新参数
          update = lr * m_hat / (sqrt(v_hat) + epsilon)
          params = params - update
  ```

* **优缺点:**

  *   **优点:**
      *   **结合了 Momentum 和 RMSprop 的优点:** 既有动量加速，又有自适应学习率。
      *   **计算高效，内存占用少:** 只需要存储一阶和二阶矩向量。
      *   **通常对超参数选择不敏感:** 推荐的默认值 $\beta_1=0.9, \beta_2=0.999, \epsilon=10^{-8}$ 在很多情况下效果良好。
      *   **适用于大数据集和高维参数空间:** 在深度学习中表现出色，是目前最常用的优化器之一。
  *   **缺点:**
      *   **可能在某些情况下不收敛:** 有研究指出 Adam 在某些优化问题上可能无法收敛到最优解，或者泛化性能不如 SGD+Momentum。
      *   **需要调整学习率 $\eta$:** 虽然对 $\beta$ 参数不敏感，但学习率 $\eta$ 仍然是一个关键的超参数。
      *   **AdamW 改进:** Adam 的原始实现中 L2 正则化（权重衰减）与梯度更新耦合可能不理想，AdamW 等变体对其进行了改进。

---

### **6. Nadam (Nesterov-accelerated Adaptive Moment Estimation)**

*   **核心思想:**
    Nadam 试图将 **Nesterov 加速梯度 (NAG)** 的“预见性”优势融入 **Adam** 优化器中。回顾 NAG，它通过在“预测”的未来位置计算梯度来获得更优的更新方向。Adam 已经包含了动量（一阶矩估计 $m_t$）。Nadam 的目标是将 NAG 的这种前瞻性思想应用于 Adam 的动量部分，期望能比标准 Adam 更快地收敛，尤其是在梯度变化较多的复杂优化场景中。它通过修改 Adam 更新规则中动量项的应用方式来实现这一点。

*   **公式与步骤:**
    $$
    \begin{aligned}
    \text{动量更新} &: m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t \\
    \text{梯度累积} &: v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2 \\
    \text{偏差校正} &: \hat{m}_t = \frac{m_t}{1-\beta_1^t}, \hat{v}_t = \frac{v_t}{1-\beta_2^t} \\
    \text{Nesterov修正} &: \hat{m}_t' = \beta_1 \hat{m}_t + \frac{(1-\beta_1)g_t}{1-\beta_1^t} \\
    \text{参数更新} &: \theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t'}{\sqrt{\hat{v}_t}+\epsilon}
    \end{aligned}
    $$
    Nadam 的步骤与 Adam 非常相似，主要区别在于参数更新时如何应用动量项。
    
    1.  初始化一阶矩估计 $m_0 = 0$ 和二阶矩估计 $v_0 = 0$。初始化时间步 $t = 0$。
    2.  设置学习率 $\eta$，一阶矩衰减系数 $\beta_1$ (通常 0.9)，二阶矩衰减系数 $\beta_2$ (通常 0.999)，以及稳定项 $\epsilon$ (e.g., $10^{-8}$)。
    3.  在每个时间步 $t$ (从 1 开始)：
        a. $t \leftarrow t + 1$
        b. 计算当前参数 $\theta_{t-1}$ 下的梯度 $g_t = \nabla J(\theta_{t-1})$。
        c. **更新有偏一阶矩估计 (同 Adam):**
        $$
        m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
        $$
        d. **更新有偏二阶矩估计 (同 Adam):**
        $$
           v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
        $$
        e. **计算偏差修正后的一阶矩估计 (同 Adam):**
        $$
        \hat{m}_t = \frac{m_t}{1 - \beta_1^t}
        $$
        f. **计算偏差修正后的二阶矩估计 (同 Adam):**
        $$
           \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
        $$
        g. **计算参数更新 (Nadam 的核心区别):**
        $$
        \theta_t = \theta_{t-1} - \eta \frac{\beta_1 \hat{m}_t + \frac{(1-\beta_1)g_t}{1-\beta_1^t}}{\sqrt{\hat{v}_t} + \epsilon}
        $$
           *   注意这个更新项与 Adam 的 $\eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$ 不同。它显式地结合了当前偏差修正后的动量项 $\beta_1 \hat{m}_t$ 和当前梯度经过偏差修正（针对当前步 $t$）的部分 $\frac{(1-\beta_1)g_t}{1-\beta_1^t}$。这可以理解为将 Nesterov 的思想（应用动量后再结合当前梯度）融入了 Adam 的框架。
           *   其实如果你展开来看的话就是在计算Adam计算$\hat{m}_t$时将分子部分的$m_{t-1}$改为了$m_{t}$，即先算出来t时刻动量再将t时刻动量替换t-1时刻动量进行计算以表示Nesterov 的思想。
    
*   **伪代码实现:**

    ```python
    # lr: 学习率
    # beta1, beta2: 衰减系数 (e.g., 0.9, 0.999)
    # epsilon: 数值稳定项 (e.g., 1e-8)
    # params: 模型参数
    # m: 一阶矩估计 (初始化为 0)
    # v: 二阶矩估计 (初始化为 0)
    # t: 时间步 (初始化为 0)
    # eval_grad: 计算梯度的函数 (通常基于 mini-batch)

    for i in range(epochs):
        for batch_data in dataset.batch(batch_size):
            t = t + 1
            grad = eval_grad(losses, batch_data, params)

            # 更新有偏矩估计
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad * grad

            # 计算偏差修正 (注意 m_hat 的计算方式与 Adam 相同)
            m_hat = m / (1 - beta1**t)
            v_hat = v / (1 - beta2**t)

            # 计算 Nadam 更新项 (核心区别)
            # Nadam momentum part combines bias-corrected momentum and bias-corrected current gradient
            m_nesterov = beta1 * m_hat + (1 - beta1) * grad / (1 - beta1**t) # Note: grad term is also effectively bias-corrected for step t

            # 更新参数
            update = lr * m_nesterov / (sqrt(v_hat) + epsilon)
            params = params - update
    ```

*   **优缺点:**
    *   **优点:**
        *   **结合 Nesterov 动量:** 继承了 NAG 的“前瞻性”，可能比 Adam 在某些梯度变化剧烈的问题上收敛更快或效果更好。
        *   **保留 Adam 优点:** 仍然具有自适应学习率和动量特性。
    *   **缺点:**
        *   **理论与实践效果:** 虽然理论上融合了 NAG，但在实践中其相对于 Adam 的优势并不总是显著或一致，有时效果提升有限。
        *   **超参数调整:** 仍然需要调整学习率 $\eta$ 和衰减系数 $\beta_1, \beta_2, \epsilon$。
        *   **复杂度:** 实现略微比 Adam 复杂一点。

---

### **7. AdamW (Adam with Decoupled Weight Decay)**

*   **核心思想:**
    AdamW 专注于解决标准 Adam 优化器在应用 **L2 正则化（权重衰减 Weight Decay）** 时的一个理论和实践上的问题。在传统的 L2 正则化中，正则化项被加到损失函数中，其梯度（等于 $\lambda \theta$，其中 $\lambda$ 是权重衰减系数）被加到原始的梯度 $g_t$ 上。然后，Adam（以及 AdaGrad, RMSprop）的自适应学习率机制（分母 $\sqrt{\hat{v}_t+\epsilon}$）会同时作用于原始梯度和这个正则化梯度。Loshchilov & Hutter 指出，这种耦合方式可能并不理想：
    
    1.  权重衰减的目的应该是让权重**直接**趋向于零，其效果应该独立于梯度的历史大小。
    2.  Adam 的自适应学习率是为适应梯度本身的尺度而设计的，将其应用于固定的权重衰减项可能不合适，导致对大梯度参数的正则化效果减弱。
    AdamW 通过**解耦 (decouple)** 权重衰减和梯度更新来解决这个问题：它在 Adam 计算出基于梯度和动量的更新步长之后，**独立地**将权重衰减直接应用于参数更新步骤。
    
*   **公式与步骤:**
    $$
    \begin{aligned}
    \text{动量/梯度累积} &: \text{同Adam(但是在计算梯度时不包含L2 正则项的梯度)}\\
    \text{参数更新} &: \theta_t = \theta_{t-1} - \eta \left( \frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon} + \lambda \theta_{t-1} \right)
    \end{aligned}
    $$
    AdamW 的核心计算与 Adam 相同，区别仅在于最后的参数更新步骤。
    
    1.  初始化一阶矩估计 $m_0 = 0$ 和二阶矩估计 $v_0 = 0$。初始化时间步 $t = 0$。
    2.  设置学习率 $\eta$，一阶矩衰减系数 $\beta_1$ (通常 0.9)，二阶矩衰减系数 $\beta_2$ (通常 0.999)，稳定项 $\epsilon$ (e.g., $10^{-8}$)，以及**权重衰减系数 $\lambda$** (e.g., 0.01)。
    3.  在每个时间步 $t$ (从 1 开始)：
        a. $t \leftarrow t + 1$
        b. 计算当前参数 $\theta_{t-1}$ 下的梯度 $g_t = \nabla J(\theta_{t-1})$ (注意：**不包含** L2 正则项的梯度)。
        c. 更新有偏一阶矩估计: $m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$
        d. 更新有偏二阶矩估计: $v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2$
        e. 计算偏差修正后的一阶矩估计: $\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$
        f. 计算偏差修正后的二阶矩估计: $\hat{v}_t = \frac{v_t}{1 - \beta_2^t}$
        g. **计算 Adam 更新步长 (不含权重衰减):**
           $$ \Delta \theta_t^{\text{Adam}} = \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$
        h. **应用解耦的权重衰减并更新参数 (AdamW 的核心区别):**
           $$ \theta_t = \theta_{t-1} - \Delta \theta_t^{\text{Adam}} - \eta \lambda \theta_{t-1} $$
           *   注意权重衰减项 $\eta \lambda \theta_{t-1}$ 是**独立于** Adam 基于梯度的更新步长 $\Delta \theta_t^{\text{Adam}}$，直接从 $\theta_{t-1}$ 中减去的。这里的权重衰减效果与当前学习率 $\eta$ 成正比。
    
*   **伪代码实现:**

    ```python
    # lr: 学习率
    # beta1, beta2: 衰减系数 (e.g., 0.9, 0.999)
    # epsilon: 数值稳定项 (e.g., 1e-8)
    # weight_decay: 权重衰减系数 (lambda, e.g., 0.01)
    # params: 模型参数
    # m: 一阶矩估计 (初始化为 0)
    # v: 二阶矩估计 (初始化为 0)
    # t: 时间步 (初始化为 0)
    # eval_grad: 计算梯度的函数 (不含 L2 正则项梯度)

    for i in range(epochs):
        for batch_data in dataset.batch(batch_size):
            t = t + 1
            # 计算原始梯度 (不含 L2)
            grad = eval_grad(losses, batch_data, params)

            # 更新有偏矩估计
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad * grad

            # 计算偏差修正
            m_hat = m / (1 - beta1**t)
            v_hat = v / (1 - beta2**t)

            # 计算 Adam 的更新量 (不含权重衰减)
            adam_update = lr * m_hat / (sqrt(v_hat) + epsilon)

            # 应用解耦的权重衰减并更新参数
            params = params - adam_update - lr * weight_decay * params # 直接对 params 操作
            # (或者 params = (1 - lr * weight_decay) * params - adam_update，效果相同)
    ```

*   **优缺点:**
    *   **优点:**
        *   **更有效的权重衰减:** 理论上更合理，实践中通常能带来更好的泛化性能，尤其是在需要较强正则化的任务中。
        *   **提高了模型性能:** 在许多基准测试和实际应用中，AdamW 的表现优于或等于带有 L2 正则化的标准 Adam。
        *   **成为现代标准:** 在许多现代深度学习库和 Transformer 模型训练中，AdamW 已成为默认或推荐的优化器。
    *   **缺点:**
        *   **需要调整权重衰减系数 $\lambda$:** 仍然需要仔细选择合适的 $\lambda$ 值，这本身就是一个重要的超参数。
        *   **与学习率调度交互:** 权重衰减的效果现在与学习率 $\eta$ 直接相关，学习率调度会同时影响梯度更新和权重衰减的强度，需要注意这种交互。

---

### **8. RAdam (Rectified Adam)**

*   **核心思想:**
    RAdam 旨在解决标准 Adam 在训练**初期**可能存在的**收敛不稳定**问题。这个问题源于自适应学习率（分母 $\sqrt{\hat{v}_t+\epsilon}$）在早期计算时依赖的二阶矩估计 $v_t$ 方差过大。因为 $v_t$ 是基于少量样本计算的指数移动平均，早期估计不准确，可能导致学习率过大或过小，使模型训练在开始阶段震荡甚至发散。RAdam 的核心思想是：
    
    1.  **检测自适应学习率方差:** 它计算一个衡量 $v_t$ 的 EMA 方差是否足够小的项 $\rho_t$。
    2.  **动态修正 (Rectify):**
        *   **如果方差过大** ($\rho_t$ 小于某个阈值，例如 4 或 5)，说明自适应学习率不可靠，RAdam 此时**暂时关闭**自适应调整，**仅使用 Momentum** 进行更新（相当于回退到 SGD + Momentum）。
        *   **如果方差足够小** ($\rho_t$ 大于阈值)，说明自适应学习率已经比较稳定，RAdam **启用**自适应调整，并计算一个**修正因子 $r_t$** 来进一步调整 Adam 的更新步长。
        本质上，RAdam 在训练初期引入了一个**自动的“预热”(warm-up)** 阶段，等自适应学习率稳定后再完全启用 Adam 的机制。
    
*   **公式与步骤:**
    $$
    \begin{aligned}
    \text{动量/梯度累积} &: \text{同Adam} \\
    \text{方差阈值} &: \rho_\infty = \frac{2}{1-\beta_2}-1,\ \rho_t = \rho_\infty - \frac{2t\beta_2^t}{1-\beta_2^t} \\
    \text{整流系数} &: r_t = \sqrt{\frac{(\rho_t-4)(\rho_t-2)\rho_\infty}{(\rho_\infty-4)(\rho_\infty-2)\rho_t}} \text{ if } \rho_t>5 \text{ else } 1 \\
    \text{参数更新} &: \theta_t = \theta_{t-1} - \eta r_t \frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}
    \end{aligned}
    $$
    
    
    1.  初始化一阶矩估计 $m_0 = 0$ 和二阶矩估计 $v_0 = 0$。初始化时间步 $t = 0$。
    2.  设置学习率 $\eta$，$\beta_1$ (通常 0.9)，$\beta_2$ (通常 0.999)，$\epsilon$ (e.g., $10^{-8}$)。计算 $\rho_{\infty} = \frac{2}{1-\beta_2} - 1$ (EMA 的最大可能长度)。
    3.  在每个时间步 $t$ (从 1 开始)：
        a. $t \leftarrow t + 1$
        b. 计算梯度 $g_t = \nabla J(\theta_{t-1})$。
        c. 更新有偏一阶矩估计: $m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$
        d. 更新有偏二阶矩估计: $v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2$
        e. 计算偏差修正后的一阶矩估计: $\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$
        f. **计算 $\rho_t$ (衡量 EMA 方差):**
           $$ \rho_t = \rho_{\infty} - \frac{2t \beta_2^t}{1 - \beta_2^t} $$
        g. **判断是否启用自适应学习率并计算修正项 $r_t$:**
           *   **如果 $\rho_t > 4$** (原论文阈值，有时实现用 5):
               *   计算修正项: $r_t = \sqrt{\frac{(\rho_t - 4)(\rho_t - 2)\rho_{\infty}}{(\rho_{\infty} - 4)(\rho_{\infty} - 2)\rho_t}}$
               *   计算偏差修正后的二阶矩估计: $\hat{v}_t = \frac{v_t}{1 - \beta_2^t}$ (只需要在此时计算)
               *   **更新参数 (使用修正后的 Adam):**
                  $$ \theta_t = \theta_{t-1} - \eta \cdot r_t \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$
           *   **如果 $\rho_t \le 4$:**
               *   **更新参数 (仅使用 Momentum):**
                  $$ \theta_t = \theta_{t-1} - \eta \cdot \hat{m}_t $$
                  (注意：这里不使用二阶矩 $\hat{v}_t$)
    
*   **伪代码实现:**

    ```python
    # lr: 学习率
    # beta1, beta2: 衰减系数 (e.g., 0.9, 0.999)
    # epsilon: 数值稳定项 (e.g., 1e-8)
    # params: 模型参数
    # m: 一阶矩估计 (初始化为 0)
    # v: 二阶矩估计 (初始化为 0)
    # t: 时间步 (初始化为 0)
    # eval_grad: 计算梯度的函数 (通常基于 mini-batch)

    rho_inf = 2 / (1 - beta2) - 1

    for i in range(epochs):
        for batch_data in dataset.batch(batch_size):
            t = t + 1
            grad = eval_grad(losses, batch_data, params)

            # 更新有偏矩估计
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad * grad

            # 修正一阶矩
            m_hat = m / (1 - beta1**t)

            # 计算 rho_t
            rho_t = rho_inf - (2 * t * (beta2**t)) / (1 - beta2**t)

            # 判断是否启用自适应项
            if rho_t > 4: # Check variance sufficiency threshold
                # 计算修正二阶矩
                v_hat = v / (1 - beta2**t)
                # 计算修正因子 r_t
                r_t_num = (rho_t - 4) * (rho_t - 2) * rho_inf
                r_t_den = (rho_inf - 4) * (rho_inf - 2) * rho_t
                r_t = sqrt(r_t_num / r_t_den)
                # 更新参数 (使用修正的 Adam)
                update = lr * r_t * m_hat / (sqrt(v_hat) + epsilon)
            else:
                # 更新参数 (仅使用 Momentum)
                update = lr * m_hat

            params = params - update
    ```

*   **优缺点:**
    *   **优点:**
        *   **提高初期稳定性:** 通过自动“预热”机制，有效缓解了 Adam 在训练初期的不稳定和对学习率敏感的问题。
        *   **减少对学习率预热的需求:** 在很多需要手动设置学习率预热 (warm-up) 的场景，RAdam 可以自动处理，简化了调参。
        *   **通常更鲁棒:** 对不同的学习率选择和初始化可能比标准 Adam 更鲁棒。
    *   **缺点:**
        *   **实现略复杂:** 相比 Adam，增加了计算 $\rho_t$ 和 $r_t$ 的逻辑。
        *   **性能提升不保证:** 在 Adam 本身表现就很好的问题上，RAdam 可能不会带来显著提升，甚至可能略慢（由于初期的非自适应阶段）。
        *   **阈值选择:** 阈值（如 4 或 5）的选择可能对性能有轻微影响。



参考：

https://github.com/luhengshiwo/LLMForEverybody/tree/main

[深度学习的优化器（各类 optimizer 的原理、优缺点及数学推导） - FromL77 - 博客园](https://www.cnblogs.com/froml77/p/14956375.html)
